# Ultralytics YOLO ğŸš€, AGPL-3.0 license

# å¯¼å…¥æ‰€éœ€çš„Pythonåº“
from functools import partial  # ç”¨äºåˆ›å»ºåå‡½æ•°
from pathlib import Path  # ç”¨äºå¤„ç†æ–‡ä»¶è·¯å¾„
import torch  # PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
from ultralytics.utils import IterableSimpleNamespace, yaml_load  # YOLOå·¥å…·ç±»
from ultralytics.utils.checks import check_yaml  # YAMLé…ç½®æ£€æŸ¥å·¥å…·
from .botsort_tracker import BOTSORT  # BoT-SORTè·Ÿè¸ªå™¨
from .bytetrack_tracker import BYTETracker  # ByteTrackè·Ÿè¸ªå™¨

# å®šä¹‰è·Ÿè¸ªå™¨ç±»å‹æ˜ å°„å­—å…¸ï¼Œæ”¯æŒByteTrackå’ŒBoT-SORTä¸¤ç§è·Ÿè¸ªå™¨
TRACKER_MAP = {"bytetrack": BYTETracker, "botsort": BOTSORT}


def on_predict_start(predictor: object, persist: bool = False) -> None:
    """
    åœ¨é¢„æµ‹å¼€å§‹æ—¶åˆå§‹åŒ–ç›®æ ‡è·Ÿè¸ªå™¨
    
    å‚æ•°è¯´æ˜:
        predictor: é¢„æµ‹å™¨å¯¹è±¡
        persist: æ˜¯å¦ä¿æŒå·²å­˜åœ¨çš„è·Ÿè¸ªå™¨çŠ¶æ€
    
    å¼‚å¸¸:
        AssertionError: å½“è·Ÿè¸ªå™¨ç±»å‹ä¸æ˜¯'bytetrack'æˆ–'botsort'æ—¶æŠ›å‡º
    """
    # å¦‚æœå·²ç»å­˜åœ¨è·Ÿè¸ªå™¨ä¸”éœ€è¦ä¿æŒçŠ¶æ€ï¼Œåˆ™ç›´æ¥è¿”å›
    if hasattr(predictor, "trackers") and persist:
        return

    # åŠ è½½å¹¶æ£€æŸ¥è·Ÿè¸ªå™¨é…ç½®æ–‡ä»¶
    tracker = check_yaml(predictor.args.tracker)
    cfg = IterableSimpleNamespace(**yaml_load(tracker))

    # éªŒè¯è·Ÿè¸ªå™¨ç±»å‹æ˜¯å¦æ”¯æŒ
    if cfg.tracker_type not in {"bytetrack", "botsort"}:
        raise AssertionError(f"ç›®å‰ä»…æ”¯æŒ'bytetrack'å’Œ'botsort'è·Ÿè¸ªå™¨ï¼Œä½†æ”¶åˆ°äº†'{cfg.tracker_type}'")

    # åˆå§‹åŒ–è·Ÿè¸ªå™¨åˆ—è¡¨
    trackers = []
    for _ in range(predictor.dataset.bs):
        # æ ¹æ®é…ç½®åˆ›å»ºå¯¹åº”ç±»å‹çš„è·Ÿè¸ªå™¨å®ä¾‹
        tracker = TRACKER_MAP[cfg.tracker_type](args=cfg, frame_rate=30)
        trackers.append(tracker)
        # éæµå¼æ¨¡å¼ä¸‹åªéœ€è¦ä¸€ä¸ªè·Ÿè¸ªå™¨
        if predictor.dataset.mode != "stream":
            break
    predictor.trackers = trackers
    # åˆå§‹åŒ–è§†é¢‘è·¯å¾„åˆ—è¡¨ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦é‡ç½®è·Ÿè¸ªå™¨
    predictor.vid_path = [None] * predictor.dataset.bs


def on_predict_postprocess_end(predictor: object, persist: bool = False) -> None:
    """
    åœ¨é¢„æµ‹åå¤„ç†é˜¶æ®µç»“æŸæ—¶æ›´æ–°ç›®æ ‡è·Ÿè¸ªç»“æœ
    
    å‚æ•°è¯´æ˜:
        predictor: åŒ…å«é¢„æµ‹ç»“æœçš„é¢„æµ‹å™¨å¯¹è±¡
        persist: æ˜¯å¦ä¿æŒè·Ÿè¸ªå™¨çŠ¶æ€
    """
    # è·å–å½“å‰æ‰¹æ¬¡çš„è·¯å¾„å’ŒåŸå§‹å›¾åƒ
    path, im0s = predictor.batch[:2]

    # åˆ¤æ–­ä»»åŠ¡ç±»å‹å’Œæ•°æ®æ¨¡å¼
    is_obb = predictor.args.task == "obb"  # æ˜¯å¦ä¸ºæœ‰å‘è¾¹ç•Œæ¡†ä»»åŠ¡
    is_stream = predictor.dataset.mode == "stream"  # æ˜¯å¦ä¸ºæµå¼å¤„ç†æ¨¡å¼
    
    # éå†æ¯ä¸ªå›¾åƒè¿›è¡Œå¤„ç†
    for i in range(len(im0s)):
        # è·å–å¯¹åº”çš„è·Ÿè¸ªå™¨
        tracker = predictor.trackers[i if is_stream else 0]
        # æ„å»ºè§†é¢‘ä¿å­˜è·¯å¾„
        vid_path = predictor.save_dir / Path(path[i]).name
        
        # å¦‚æœè§†é¢‘è·¯å¾„å‘ç”Ÿå˜åŒ–ä¸”ä¸ä¿æŒçŠ¶æ€ï¼Œåˆ™é‡ç½®è·Ÿè¸ªå™¨
        if not persist and predictor.vid_path[i if is_stream else 0] != vid_path:
            tracker.reset()
            predictor.vid_path[i if is_stream else 0] = vid_path

        # è·å–æ£€æµ‹ç»“æœå¹¶è½¬æ¢ä¸ºnumpyæ•°ç»„
        det = (predictor.results[i].obb if is_obb else predictor.results[i].boxes).cpu().numpy()
        if len(det) == 0:
            continue
            
        # ä½¿ç”¨è·Ÿè¸ªå™¨æ›´æ–°ç›®æ ‡çŠ¶æ€
        tracks = tracker.update(det, im0s[i])
        if len(tracks) == 0:
            continue
            
        # æ›´æ–°é¢„æµ‹ç»“æœ
        idx = tracks[:, -1].astype(int)
        predictor.results[i] = predictor.results[i][idx]
        
        # æ›´æ–°è¾¹ç•Œæ¡†ä¿¡æ¯
        update_args = {"obb" if is_obb else "boxes": torch.as_tensor(tracks[:, :-1])}
        predictor.results[i].update(**update_args)


def register_tracker(model: object, persist: bool) -> None:
    """
    ä¸ºæ¨¡å‹æ³¨å†Œç›®æ ‡è·Ÿè¸ªå›è°ƒå‡½æ•°
    
    å‚æ•°è¯´æ˜:
        model: éœ€è¦æ³¨å†Œè·Ÿè¸ªåŠŸèƒ½çš„æ¨¡å‹å¯¹è±¡
        persist: æ˜¯å¦ä¿æŒè·Ÿè¸ªå™¨çŠ¶æ€
    """
    # æ³¨å†Œé¢„æµ‹å¼€å§‹å’Œåå¤„ç†ç»“æŸæ—¶çš„å›è°ƒå‡½æ•°
    model.add_callback("on_predict_start", partial(on_predict_start, persist=persist))
    model.add_callback("on_predict_postprocess_end", partial(on_predict_postprocess_end, persist=persist))
