#!/usr/bin/env python3
"""
æ— äººæœºå¤šç›®æ ‡è·Ÿè¸ªç³»ç»Ÿ - å®˜æ–¹API + ä¼˜åŒ–GUIç‰ˆæœ¬
æ”¯æŒ8Kè§†é¢‘å®æ—¶å¤„ç†ï¼Œå…·å¤‡å®Œæ•´çš„è½¨è¿¹å¯è§†åŒ–å’Œæ€§èƒ½ç›‘æ§åŠŸèƒ½

ä¸»è¦ç‰¹æ€§ï¼š
- ä½¿ç”¨YOLOå®˜æ–¹å†…ç½®è·Ÿè¸ªå™¨ï¼ˆBoT-SORT/ByteTrackï¼‰
- æ™ºèƒ½è½¨è¿¹ç»˜åˆ¶ï¼šé»„è‰²IDæ˜¾ç¤ºåœ¨è½¨è¿¹èµ·å§‹ç‚¹ï¼Œç»¿è‰²è½¨è¿¹çº¿
- è¯¦ç»†çš„æ€§èƒ½ç»Ÿè®¡å’Œç›‘æ§
- å¯è°ƒæ•´çª—å£å¤§å°å’Œå…¨å±æ˜¾ç¤º
- æ”¯æŒæš‚åœ/ç»§ç»­æ’­æ”¾
- å®æ—¶è·Ÿè¸ªå™¨åˆ‡æ¢åŠŸèƒ½

æ ¸å¿ƒç®—æ³•ï¼š
- YOLOå®˜æ–¹å†…ç½®è·Ÿè¸ªå™¨ï¼ˆé»˜è®¤BoT-SORTï¼‰
- å®˜æ–¹æ¨èçš„persist=Trueé€å¸§å¤„ç†
- å®Œå…¨å¯¹é½å®˜æ–¹æœ€ä½³å®è·µ

ä½¿ç”¨è¯´æ˜ï¼š
- Q: é€€å‡ºç¨‹åº
- R: é‡ç½®çª—å£å¤§å°
- F: åˆ‡æ¢å…¨å±
- Space: æš‚åœ/ç»§ç»­
- T: åˆ‡æ¢è·Ÿè¸ªå™¨ç±»å‹

- é¼ æ ‡å·¦é”®: æ˜¾ç¤ºåæ ‡

"""

# å¯¼å…¥æ‰€éœ€çš„Pythonåº“
import os  # ç”¨äºæ–‡ä»¶å’Œè·¯å¾„æ“ä½œ
import threading  # å¤šçº¿ç¨‹æ”¯æŒ
import queue  # çº¿ç¨‹é—´é€šä¿¡é˜Ÿåˆ—
import torch  # PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
import time  # ç”¨äºæ€§èƒ½è®¡æ—¶å’Œå»¶è¿Ÿæ§åˆ¶
from ultralytics import YOLO  # YOLOç›®æ ‡æ£€æµ‹æ¨¡å‹
from collections import defaultdict  # ç”¨äºè½¨è¿¹å†å²è®°å½•çš„é»˜è®¤å­—å…¸
import cv2  # OpenCVå›¾åƒå¤„ç†åº“
import numpy as np  # æ•°å€¼è®¡ç®—åº“
from tqdm import tqdm  # è¿›åº¦æ¡æ˜¾ç¤º


# ä½¿ç”¨YOLOå®˜æ–¹å†…ç½®è·Ÿè¸ªå™¨ï¼Œæ— éœ€å¯¼å…¥è‡ªå®šä¹‰è·Ÿè¸ªå™¨

# å®šä¹‰å¯ç”¨çš„è·Ÿè¸ªå™¨ç±»å‹
AVAILABLE_TRACKERS = ["botsort", "bytetrack"]

def get_tracker_config(tracker_type):
    """
    è·å–è·Ÿè¸ªå™¨é…ç½®

    å‚æ•°:
        tracker_type: è·Ÿè¸ªå™¨ç±»å‹ ("botsort", "bytetrack")

    è¿”å›:
        è·Ÿè¸ªå™¨é…ç½®å­—ç¬¦ä¸²æˆ–Noneï¼ˆNoneè¡¨ç¤ºä½¿ç”¨é»˜è®¤BoT-SORTï¼‰
    """
    if tracker_type == "bytetrack":
        return "/data2/wuyuchen/Tracking_benchmark/cfg/bytetrack.yaml"
    elif tracker_type == "botsort":
        return "/data2/wuyuchen/Tracking_benchmark/cfg/botsort.yaml"
    else:
        return None  # ä½¿ç”¨é»˜è®¤è·Ÿè¸ªå™¨ï¼ˆBoT-SORTï¼‰

def mouse_callback(event, x, y, flags, param):
    """
    é¼ æ ‡å›è°ƒå‡½æ•° - ç‚¹å‡»æ˜¾ç¤ºåæ ‡ä½ç½®
    """
    _ = flags, param  # å¿½ç•¥æœªä½¿ç”¨çš„å‚æ•°
    if event == cv2.EVENT_LBUTTONDOWN:
        print(f"Mouse click at: ({x}, {y})")
    elif event == cv2.EVENT_RBUTTONDOWN:
        print(f"Right click at: ({x}, {y})")



def draw_tracks(frame, track_history):
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶ç›®æ ‡è½¨è¿¹å’ŒIDæ ‡è¯†

    è½¨è¿¹å¯è§†åŒ–è¯´æ˜ï¼š
    - ç»¿è‰²çº¿æ¡ï¼šç›®æ ‡çš„å†å²ç§»åŠ¨è½¨è¿¹
    - é»„è‰²æ•°å­—ï¼šç›®æ ‡çš„å”¯ä¸€IDï¼Œæ˜¾ç¤ºåœ¨è½¨è¿¹èµ·å§‹ç‚¹
    - IDæ•°å­—å¯èƒ½ä¸è¿ç»­ï¼ˆå¦‚1,3,9,30ï¼‰ï¼Œè¿™æ˜¯æ­£å¸¸ç°è±¡ï¼Œè¡¨ç¤ºä¸­é—´çš„IDå·²è¢«åˆ é™¤

    å‚æ•°è¯´æ˜ï¼š
        frame: å½“å‰è§†é¢‘å¸§
        track_history: åŒ…å«æ‰€æœ‰ç›®æ ‡è½¨è¿¹å†å²çš„å­—å…¸
                      æ ¼å¼: {track_id: [(x1,y1), (x2,y2), ...]}

    è¿”å›å€¼ï¼š
        ç»˜åˆ¶å®Œè½¨è¿¹çš„å›¾åƒå¸§
    """
    # éå†æ¯ä¸ªç›®æ ‡çš„è½¨è¿¹å†å²
    for track_id, track in track_history.items():
        # ç»˜åˆ¶è½¨è¿¹çº¿ï¼šå¦‚æœè½¨è¿¹ç‚¹æ•°å¤§äº1ï¼Œç”¨ç»¿è‰²çº¿æ¡è¿æ¥æ‰€æœ‰å†å²ä½ç½®
        if len(track) > 1:
            points = np.array(track).astype(np.int32).reshape((-1, 1, 2))
            cv2.polylines(frame, [points], isClosed=False, color=(0, 255, 0), thickness=4)

        # ç»˜åˆ¶ç›®æ ‡IDï¼šåœ¨è½¨è¿¹èµ·å§‹ç‚¹æ˜¾ç¤ºé»„è‰²IDæ•°å­—
        if len(track) > 0:
            start_point = tuple(np.array(track[0]).astype(int))
            cv2.putText(
                frame,
                str(track_id),  # æ˜¾ç¤ºè½¨è¿¹IDï¼ˆå¯èƒ½ä¸è¿ç»­ï¼Œå¦‚1,3,9,30ç­‰ï¼‰
                start_point,    # æ˜¾ç¤ºä½ç½®ï¼šè½¨è¿¹çš„ç¬¬ä¸€ä¸ªç‚¹ï¼ˆèµ·å§‹ä½ç½®ï¼‰
                cv2.FONT_HERSHEY_SIMPLEX,
                1.2,            # å­—ä½“å¤§å°ï¼ˆä»3å‡å°åˆ°1.2ï¼Œæ›´åˆé€‚çš„å¤§å°ï¼‰
                (0, 255, 255),  # é»„è‰² (BGRæ ¼å¼: è“=0, ç»¿=255, çº¢=255)
                2,              # å­—ä½“ç²—ç»†ï¼ˆä»3å‡å°åˆ°2ï¼‰
                cv2.LINE_AA     # æŠ—é”¯é½¿
            )
    return frame

# åˆå§‹åŒ–YOLOæ¨¡å‹
# ä½¿ç”¨é¢„è®­ç»ƒçš„æƒé‡æ–‡ä»¶'best.pt'
model = YOLO("/data2/wuyuchen/Tracking_benchmark/runs/train/20250809_2327_yolo11m_imgsz1280_epoch300_bs8/weights/best.pt")

# åˆå§‹åŒ–è·Ÿè¸ªå™¨ç±»å‹
# ä½¿ç”¨å®˜æ–¹YOLOå†…ç½®è·Ÿè¸ªå™¨ï¼Œæ›´ç¨³å®šå¯é 
current_tracker = "botsort"  # å¯é€‰: "botsort" (é»˜è®¤), "bytetrack"
print(f"ğŸ”§ ä½¿ç”¨è·Ÿè¸ªå™¨: {current_tracker}")

# å…¨å±€å˜é‡ç”¨äºè·Ÿè¸ªå™¨åˆ‡æ¢
tracker_config = get_tracker_config(current_tracker)

# æ‰“å¼€è§†é¢‘æ–‡ä»¶
# æ³¨æ„ï¼šç¡®ä¿è§†é¢‘è·¯å¾„æ­£ç¡®ä¸”å¯è®¿é—®
video_path = "/data2/wuyuchen/Tracking_benchmark/data/train/1-2.avi"  # ä½¿ç”¨æ¯”èµ›éªŒè¯é›†è§†é¢‘
cap = cv2.VideoCapture(video_path)

# è·å–è§†é¢‘æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ç”¨äºä¿å­˜æ¯”èµ›ç»“æœ
video_name = os.path.splitext(os.path.basename(video_path))[0]

# è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯
fps = cap.get(cv2.CAP_PROP_FPS)  # è§†é¢‘å¸§ç‡
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # è§†é¢‘å®½åº¦
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # è§†é¢‘é«˜åº¦
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # æ€»å¸§æ•°

# è®¾ç½®å­å›¾åˆ†å‰²å‚æ•°
# ç”±äºåŸè§†é¢‘åˆ†è¾¨ç‡è¾ƒé«˜ï¼Œéœ€è¦åˆ†å—å¤„ç†ä»¥æé«˜æ•ˆç‡
sub_width = 960  # å­å›¾å®½åº¦
sub_height = 1080  # å­å›¾é«˜åº¦
cols = width // sub_width  # æ°´å¹³åˆ†å‰²æ•°
rows = height // sub_height  # å‚ç›´åˆ†å‰²æ•°

# åˆå§‹åŒ–è½¨è¿¹å†å²è®°å½•
# ä½¿ç”¨defaultdictè‡ªåŠ¨åˆ›å»ºæ–°ç›®æ ‡çš„è½¨è¿¹åˆ—è¡¨
track_history = defaultdict(lambda: [])


frame_processing_times = []  # å­˜å‚¨æ¯å¸§çš„å¤„ç†æ—¶é—´

# åˆ›å»ºå¯è°ƒæ•´å¤§å°çš„çª—å£
window_name = "YOLOç›®æ ‡è·Ÿè¸ªç³»ç»Ÿ(å¤šçº¿ç¨‹ç‰ˆ) - æŒ‰Qé€€å‡º"

# æ£€æŸ¥OpenCV GUIæ”¯æŒå¹¶åˆ›å»ºçª—å£
gui_available = True
try:
    # æ£€æŸ¥DISPLAYç¯å¢ƒå˜é‡
    import os
    if not os.environ.get('DISPLAY'):
        print("âš ï¸ æ²¡æœ‰DISPLAYç¯å¢ƒå˜é‡ï¼Œå°†ä½¿ç”¨æ— GUIæ¨¡å¼")
        gui_available = False
    else:
        # å°è¯•åˆ›å»ºçª—å£
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)  # å…è®¸è°ƒæ•´çª—å£å¤§å°å¹¶ä¿æŒæ¯”ä¾‹
        print("âœ… OpenCV GUIæ”¯æŒæ­£å¸¸")
except Exception as e:
    print(f"âŒ OpenCV GUIé”™è¯¯: {e}")
    print("ï¿½ å°è¯•è§£å†³æ–¹æ¡ˆ:")
    print("   1. æ£€æŸ¥DISPLAYç¯å¢ƒå˜é‡: echo $DISPLAY")
    print("   2. åœ¨MobaXtermä¸­å¯ç”¨X11è½¬å‘")
    print("   3. é‡æ–°å®‰è£…opencv-python: pip uninstall opencv-python && pip install opencv-python")
    print("   4. æˆ–å®‰è£…å¸¦GUIæ”¯æŒçš„ç‰ˆæœ¬: pip install opencv-contrib-python")
    gui_available = False
    print("âš ï¸  å°†åœ¨æ— GUIæ¨¡å¼ä¸‹è¿è¡Œï¼Œä»…æ˜¾ç¤ºå¤„ç†è¿›åº¦")

if gui_available:
    print("ï¿½ğŸ–¥ï¸  Window Controls:")
    print("   - Drag window edges to resize")
    print("   - Click top-right buttons to maximize/minimize/close")
    print("   - Press Q to exit")
    print("   - Press R to reset window size")
    print("   - Press F to toggle fullscreen")
    print("   - Press SPACE to pause/resume")
    print("   - Press T to switch tracker")
    print("   - Press S to save current frame")
    print("   - Left click to show coordinates")
else:
    print("ğŸ–¥ï¸  æ— GUIæ¨¡å¼:")
    print("   - å¤„ç†ç»“æœå°†ä¿å­˜åˆ°è¾“å‡ºç›®å½•")
    print("   - æŒ‰Ctrl+Cåœæ­¢å¤„ç†")

# åˆå§‹åŒ–æ€§èƒ½ç»Ÿè®¡
frame_processing_times = []

# åˆå§‹åŒ–çª—å£æ§åˆ¶å˜é‡
is_fullscreen = False
is_paused = False
window_initialized = False
mouse_callback_set = False

# å¸§é˜Ÿåˆ—å’Œçº¿ç¨‹ç®¡ç†
frame_queue = queue.Queue(maxsize=10)

def read_frames():
    """
    å¤šçº¿ç¨‹å¸§è¯»å–å‡½æ•°
    åœ¨åå°çº¿ç¨‹ä¸­æŒç»­è¯»å–è§†é¢‘å¸§ï¼Œæé«˜å¤„ç†æ•ˆç‡
    """
    while True:
        ret, frame = cap.read()
        if not ret:
            frame_queue.put(None)  # è¡¨ç¤ºè§†é¢‘ç»“æŸ
            break
        frame_queue.put(frame)

# å¯åŠ¨è¯»å–çº¿ç¨‹
read_thread = threading.Thread(target=read_frames, daemon=True)
read_thread.start()

# ä¸»å¤„ç†å¾ªç¯
# ä½¿ç”¨tqdmæ˜¾ç¤ºå¤„ç†è¿›åº¦
with tqdm(total=total_frames, desc="Processing Video", unit="frame") as pbar:
    while True:
        # å¼€å§‹è®¡æ—¶
        frame_start_time = time.time()

        # åˆå§‹åŒ–å„é˜¶æ®µè®¡æ—¶å™¨
        timing = {
            "read_frame": 0,  # å¸§è¯»å–æ—¶é—´
            "predict": 0,     # ç›®æ ‡æ£€æµ‹æ—¶é—´
            "track": 0,       # ç›®æ ‡è·Ÿè¸ªæ—¶é—´
            "draw": 0,        # ç»˜åˆ¶æ˜¾ç¤ºæ—¶é—´
        }

        # ä»é˜Ÿåˆ—ä¸­è·å–å¸§
        read_start = time.time()
        frame = frame_queue.get()
        if frame is None:  # å¦‚æœè¯»å–ç»“æŸï¼Œé€€å‡ºå¾ªç¯
            break
        timing["read_frame"] = time.time() - read_start

        # åˆå§‹åŒ–å­˜å‚¨åˆ—è¡¨
        sub_frames = []  # å­˜å‚¨åˆ†å‰²åçš„å­å›¾
        detections = []  # å­˜å‚¨æ£€æµ‹ç»“æœ

        # å›¾åƒåˆ†å—å¤„ç†
        # å°†å¤§åˆ†è¾¨ç‡å›¾åƒåˆ†å‰²æˆå°å—è¿›è¡Œå¤„ç†
        for row in range(rows):
            for col in range(cols):
                # è®¡ç®—å½“å‰å­å›¾çš„åæ ‡
                x1 = col * sub_width
                y1 = row * sub_height
                x2 = x1 + sub_width
                y2 = y1 + sub_height

                # æå–å­å›¾
                sub_frame = frame[y1:y2, x1:x2]
                sub_frames.append(sub_frame)

        # YOLOç›®æ ‡æ£€æµ‹
        predict_start = time.time()
        # ä½¿ç”¨GPUè¿›è¡Œæ‰¹é‡æ£€æµ‹
        results = model.predict(source=sub_frames, device=0, verbose=False)
        timing["predict"] = time.time() - predict_start

        # ç›®æ ‡è·Ÿè¸ªå¤„ç†
        track_start = time.time()
        # å¤„ç†æ£€æµ‹ç»“æœï¼Œå°†å­å›¾åæ ‡æ˜ å°„å›åŸå›¾åæ ‡
        for i, result in enumerate(results):
            row = i // cols
            col = i % cols
            x_offset = col * sub_width
            y_offset = row * sub_height

            # åæ ‡è½¬æ¢
            for box in result.boxes.data.cpu().numpy():
                x1, y1, x2, y2, conf, cls = box[:6]
                # æ·»åŠ åç§»é‡å¾—åˆ°åŸå›¾åæ ‡
                x1 += x_offset
                x2 += x_offset
                y1 += y_offset
                y2 += y_offset
                detections.append([x1, y1, x2, y2, conf, cls])

        # ğŸ”§ æ·»åŠ å…¨å±€NMSå»é‡å¤„ç†ï¼Œé¿å…é‡å¤æ£€æµ‹å¯¼è‡´IDæµªè´¹
        if len(detections) > 0:
            detections_array = np.array(detections)
            # ä½¿ç”¨YOLOçš„NMSå‡½æ•°è¿›è¡Œå»é‡
            from ultralytics.utils.ops import non_max_suppression
            import torch

            # è½¬æ¢ä¸ºtensoræ ¼å¼ [x1, y1, x2, y2, conf, cls]
            detections_tensor = torch.from_numpy(detections_array).float().unsqueeze(0)

            # åº”ç”¨NMSå»é‡ï¼ŒIoUé˜ˆå€¼è®¾ä¸º0.5ä»¥å»é™¤é‡å¤æ£€æµ‹
            nms_results = non_max_suppression(
                detections_tensor,
                conf_thres=0.25,  # ç½®ä¿¡åº¦é˜ˆå€¼
                iou_thres=0.5,    # IoUé˜ˆå€¼ï¼Œå»é™¤é‡å¤æ£€æµ‹
                max_det=300       # æœ€å¤§æ£€æµ‹æ•°é‡
            )[0]

            if nms_results is not None and len(nms_results) > 0:
                detections = nms_results.cpu().numpy()
            else:
                detections = np.array([])
        else:
            detections = np.array([])

        # ä½¿ç”¨å®˜æ–¹YOLOè·Ÿè¸ªAPI
        track_start = time.time()

        # æ ¹æ®å½“å‰è·Ÿè¸ªå™¨ç±»å‹è¿›è¡Œè·Ÿè¸ª
        if tracker_config:
            results = model.track(frame, persist=True, tracker=tracker_config)
        else:
            results = model.track(frame, persist=True)  # ä½¿ç”¨é»˜è®¤BoT-SORT

        timing["track"] = time.time() - track_start

        # ç»˜åˆ¶æ£€æµ‹å’Œè·Ÿè¸ªç»“æœ
        draw_start = time.time()

        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„è·Ÿè¸ªç»“æœ
        if results[0].boxes and results[0].boxes.is_track:
            # ç»˜åˆ¶æ£€æµ‹æ¡†ï¼ˆè°ƒæ•´çº¿æ¡ç²—ç»†ä¸ºæ›´ç»†çš„è¾¹ç•Œæ¡†ï¼Œå‡å°å­—ä½“å¤§å°ï¼‰
            anno_frame = results[0].plot(img=frame, line_width=3, font_size=0.8)

            # æ›´æ–°å’Œç»˜åˆ¶è½¨è¿¹
            boxes = results[0].boxes.xywh.cpu()
            track_ids = results[0].boxes.id.int().cpu().tolist()
            for box, track_id in zip(boxes, track_ids):
                x, y, w, h = box
                track = track_history[track_id]
                track.append((float(x), float(y)))  # è®°å½•ç›®æ ‡ä¸­å¿ƒç‚¹



            annotated_frame = draw_tracks(anno_frame, track_history)
        else:
            # æ²¡æœ‰è·Ÿè¸ªç»“æœæ—¶ï¼Œåªç»˜åˆ¶åŸå§‹å¸§å’Œç°æœ‰è½¨è¿¹
            annotated_frame = draw_tracks(frame, track_history)
            track_ids = []  # ç©ºçš„è·Ÿè¸ªIDåˆ—è¡¨

        # è°ƒæ•´å›¾åƒå¤§å°ç”¨äºæ˜¾ç¤º
        resized_image = cv2.resize(annotated_frame, (1920, 1080))
        timing["draw"] = time.time() - draw_start

        # è®°å½•æœ¬å¸§å¤„ç†æ—¶é—´
        frame_end_time = time.time()
        frame_time = frame_end_time - frame_start_time
        frame_processing_times.append({"total": frame_time, **timing})

        # åœ¨å›¾åƒä¸Šæ·»åŠ ä¿¡æ¯æ–‡å­—ï¼ˆä½¿ç”¨è‹±æ–‡é¿å…å­—ä½“é—®é¢˜ï¼‰- æ— èƒŒæ™¯æ¡†
        info_text = [
            f"Frame: {pbar.n}/{total_frames}",
            f"Progress: {(pbar.n/total_frames)*100:.1f}%",
            f"Speed: {1/frame_time:.1f} FPS" if frame_time > 0 else "Speed: Calculating...",
            f"Objects: {len(track_ids) if 'track_ids' in locals() else 0}",
            f"Tracker: {current_tracker.upper()}{' (Default)' if current_tracker == 'botsort' else ''} | Yellow ID = Track Start Point",
            f"Q:Exit | R:Reset | F:Fullscreen | Space:Pause | Click for coordinates"
        ]

        # ç›´æ¥ç»˜åˆ¶ä¿¡æ¯æ–‡å­—ï¼ˆæ— èƒŒæ™¯æ¡†ï¼‰
        for i, text in enumerate(info_text):
            cv2.putText(resized_image, text, (20, 35 + i*25),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

        # æ˜¾ç¤ºå¤„ç†åçš„å›¾åƒï¼ˆä»…åœ¨GUIå¯ç”¨æ—¶ï¼‰
        if gui_available:
            try:
                cv2.imshow(window_name, resized_image)

                # åˆå§‹åŒ–çª—å£è®¾ç½®ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡æ˜¾ç¤ºæ—¶æ‰§è¡Œï¼‰
                if not window_initialized:
                    try:
                        # ç­‰å¾…çª—å£å®Œå…¨åˆ›å»º
                        cv2.waitKey(1)
                        cv2.resizeWindow(window_name, 1280, 720)  # è®¾ç½®é»˜è®¤çª—å£å¤§å°ä¸º720p
                        cv2.moveWindow(window_name, 100, 100)  # è®¾ç½®çª—å£åˆå§‹ä½ç½®
                        window_initialized = True
                        print("âœ… Window size and position set")
                    except cv2.error as e:
                        print(f"âš ï¸ Window setup failed: {e}")
                        window_initialized = True  # é¿å…é‡å¤å°è¯•
            except cv2.error as e:
                print(f"âš ï¸ å›¾åƒæ˜¾ç¤ºå¤±è´¥: {e}")
                gui_available = False
                print("âš ï¸ åˆ‡æ¢åˆ°æ— GUIæ¨¡å¼")

        # å»¶è¿Ÿè®¾ç½®é¼ æ ‡å›è°ƒï¼ˆåœ¨çª—å£ç¨³å®šåä¸”GUIå¯ç”¨æ—¶ï¼‰
        if gui_available and window_initialized and not mouse_callback_set and pbar.n > 10:
            try:
                # æ£€æŸ¥çª—å£æ˜¯å¦å­˜åœ¨
                if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) >= 1:
                    cv2.setMouseCallback(window_name, mouse_callback)
                    mouse_callback_set = True
                    print("âœ… Mouse callback set")
                else:
                    # çª—å£è¿˜ä¸å¯è§ï¼Œç»§ç»­ç­‰å¾…
                    pass
            except cv2.error as e:
                print(f"âš ï¸ é¼ æ ‡å›è°ƒè®¾ç½®å¤±è´¥: {e}")
                mouse_callback_set = True  # é¿å…é‡å¤å°è¯•



        # æ›´æ–°è¿›åº¦æ¡
        pbar.update(1)

        # é”®ç›˜äº‹ä»¶å¤„ç†ï¼ˆä»…åœ¨GUIå¯ç”¨æ—¶ï¼‰
        if gui_available:
            key = cv2.waitKey(1) & 0xFF
            if key == ord("q"):  # æŒ‰Qé€€å‡º
                break
            elif key == ord("r"):  # æŒ‰Ré‡ç½®çª—å£å¤§å°
                try:
                    cv2.resizeWindow(window_name, 1280, 720)
                    cv2.moveWindow(window_name, 100, 100)
                    print("âœ… Window reset to default size")
                except cv2.error as e:
                    print(f"âš ï¸ Window reset failed: {e}")
            elif key == ord("f"):  # æŒ‰Fåˆ‡æ¢å…¨å±
                try:
                    if not is_fullscreen:
                        cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
                        is_fullscreen = True
                        print("âœ… Fullscreen mode enabled")
                    else:
                        cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)
                        is_fullscreen = False
                        print("âœ… Windowed mode enabled")
                except cv2.error as e:
                    print(f"âš ï¸ Fullscreen toggle failed: {e}")
            elif key == ord(" "):  # æŒ‰ç©ºæ ¼æš‚åœ/ç»§ç»­
                is_paused = not is_paused
                if is_paused:
                    print("â¸ï¸ Paused - Press SPACE to resume")
                    while is_paused:
                        key = cv2.waitKey(30) & 0xFF
                        if key == ord(" "):
                            is_paused = False
                            print("â–¶ï¸ Resumed")
                        elif key == ord("q"):
                            break
            elif key == ord("t"):  # æŒ‰Tåˆ‡æ¢è·Ÿè¸ªå™¨
                # åˆ‡æ¢è·Ÿè¸ªå™¨ç±»å‹
                current_idx = AVAILABLE_TRACKERS.index(current_tracker)
                current_tracker = AVAILABLE_TRACKERS[(current_idx + 1) % len(AVAILABLE_TRACKERS)]
                tracker_config = get_tracker_config(current_tracker)
                print(f"ğŸ”„ åˆ‡æ¢åˆ°è·Ÿè¸ªå™¨: {current_tracker}")


# æ¸…ç†èµ„æºå’Œæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
print("\nğŸ”„ æ­£åœ¨æ¸…ç†èµ„æº...")



# é‡Šæ”¾è§†é¢‘æ•è·å¯¹è±¡å’Œçª—å£
cap.release()
if gui_available:
    cv2.destroyAllWindows()
print("âœ… èµ„æºæ¸…ç†å®Œæˆ")

# æ˜¾ç¤ºè·Ÿè¸ªç»Ÿè®¡
print(f"âœ… è·Ÿè¸ªå®Œæˆï¼Œå…±å¤„ç† {len(track_history)} ä¸ªç›®æ ‡è½¨è¿¹")

# è®¡ç®—å¹¶æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
if frame_processing_times:
    print(f"\nğŸ“Š å¤„ç†å®Œæˆï¼å…±å¤„ç† {len(frame_processing_times)} å¸§")

    # è®¡ç®—å¹³å‡å¤„ç†æ—¶é—´ï¼ˆè·³è¿‡ç¬¬ä¸€å¸§ï¼Œå› ä¸ºå¯èƒ½åŒ…å«åˆå§‹åŒ–å¼€é”€ï¼‰
    if len(frame_processing_times) > 1:
        valid_times = frame_processing_times[1:]
        average_stats = {}
        for key in valid_times[0].keys():
            average_stats[key] = sum(times[key] for times in valid_times) / len(valid_times)

        print("\nâ±ï¸ å¹³å‡å¸§å¤„ç†æ—¶é—´:")
        for key, value in average_stats.items():
            if key != "total":
                percentage = (value / average_stats['total']) * 100 if average_stats['total'] > 0 else 0
                print(f"  {key}: {value:.4f}s ({percentage:.2f}%)")
        print(f"æ€»è®¡: {average_stats['total']:.4f}s")

        # è®¡ç®—å¹³å‡FPS
        if average_stats['total'] > 0:
            avg_fps = 1 / average_stats['total']
            print(f"å¹³å‡å¤„ç†é€Ÿåº¦: {avg_fps:.2f} FPS")
    else:
        print("å¤„ç†å¸§æ•°ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ç»Ÿè®¡ä¿¡æ¯")
else:
    print("æœªå¤„ç†ä»»ä½•å¸§")

print("\nğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆï¼")
