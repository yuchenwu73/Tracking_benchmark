#!/usr/bin/env python3
"""
æ— äººæœºå¤šç›®æ ‡è·Ÿè¸ªç³»ç»Ÿ - å¤šçº¿ç¨‹ä¼˜åŒ–ç‰ˆæœ¬
æ”¯æŒ8Kè§†é¢‘å®æ—¶å¤„ç†ï¼Œå…·å¤‡å®Œæ•´çš„è½¨è¿¹å¯è§†åŒ–å’Œæ€§èƒ½ç›‘æ§åŠŸèƒ½

ä¸»è¦ç‰¹æ€§ï¼š
- å¤šçº¿ç¨‹å¼‚æ­¥å¸§è¯»å–ï¼Œæå‡å¤„ç†æ•ˆç‡
- å­å›¾åˆ†å‰²å¤„ç†ï¼Œæ”¯æŒè¶…é«˜åˆ†è¾¨ç‡è§†é¢‘
- æ™ºèƒ½è½¨è¿¹ç»˜åˆ¶ï¼šé»„è‰²IDæ˜¾ç¤ºåœ¨è½¨è¿¹èµ·å§‹ç‚¹ï¼Œç»¿è‰²è½¨è¿¹çº¿
- ä¼˜åŒ–çš„IDåˆ†é…æœºåˆ¶ï¼Œå‡å°‘IDæµªè´¹
- è¯¦ç»†çš„æ€§èƒ½ç»Ÿè®¡å’Œç›‘æ§
- å¯è°ƒæ•´çª—å£å¤§å°å’Œå…¨å±æ˜¾ç¤º
- æ”¯æŒæš‚åœ/ç»§ç»­æ’­æ”¾

æ ¸å¿ƒç®—æ³•ï¼š
- YOLOç›®æ ‡æ£€æµ‹ + ByteTrackå¤šç›®æ ‡è·Ÿè¸ª
- æ”¹è¿›çš„è½¨è¿¹å…³è”ç®—æ³•ï¼Œæé«˜è·Ÿè¸ªç¨³å®šæ€§
- æ™ºèƒ½IDç®¡ç†ï¼Œå‡å°‘å› æ£€æµ‹å¤±è´¥å¯¼è‡´çš„IDè·³è·ƒ

ä½¿ç”¨è¯´æ˜ï¼š
- Q: é€€å‡ºç¨‹åº
- R: é‡ç½®çª—å£å¤§å°
- F: åˆ‡æ¢å…¨å±
- Space: æš‚åœ/ç»§ç»­
- é¼ æ ‡å·¦é”®: æ˜¾ç¤ºåæ ‡

ä½œè€…: AI Assistant
ç‰ˆæœ¬: 3.0 (æœ€ç»ˆä¼˜åŒ–ç‰ˆ)
"""

# å¯¼å…¥æ‰€éœ€çš„Pythonåº“
import os  # ç”¨äºæ–‡ä»¶å’Œè·¯å¾„æ“ä½œ
import threading  # å¤šçº¿ç¨‹æ”¯æŒ
import queue  # çº¿ç¨‹é—´é€šä¿¡é˜Ÿåˆ—
import torch  # PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
import time  # ç”¨äºæ€§èƒ½è®¡æ—¶å’Œå»¶è¿Ÿæ§åˆ¶
from ultralytics import YOLO  # YOLOç›®æ ‡æ£€æµ‹æ¨¡å‹
from collections import defaultdict  # ç”¨äºè½¨è¿¹å†å²è®°å½•çš„é»˜è®¤å­—å…¸
import cv2  # OpenCVå›¾åƒå¤„ç†åº“
import numpy as np  # æ•°å€¼è®¡ç®—åº“
from tqdm import tqdm  # è¿›åº¦æ¡æ˜¾ç¤º
# å¯¼å…¥YOLOå·¥å…·ç±» - ä¿®å¤ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜
from ultralytics.utils import IterableSimpleNamespace, YAML
from ultralytics.utils.checks import check_yaml
from ultralytics.engine.results import Results, Boxes

# åˆ›å»ºyaml_loadå‡½æ•°çš„å…¼å®¹ç‰ˆæœ¬
def yaml_load(file_path):
    """å…¼å®¹çš„YAMLåŠ è½½å‡½æ•°"""
    yaml_instance = YAML()
    return yaml_instance.load(file_path)

# å¯¼å…¥è·Ÿè¸ªå™¨å®ç°
from tracker.bytetrack_tracker import BYTETracker
from tracker.botsort_tracker import BOTSORT

# å®šä¹‰å¯ç”¨çš„è·Ÿè¸ªå™¨æ˜ å°„å­—å…¸
# æ”¯æŒä¸¤ç§è·Ÿè¸ªå™¨ï¼šByteTrackå’ŒBoT-SORT
TRACKER_MAP = {"bytetrack": BYTETracker, "botsort": BOTSORT}

def initialize_tracker(tracker_yaml: str, frame_rate: int = 30):
    """
    åˆå§‹åŒ–ç›®æ ‡è·Ÿè¸ªå™¨

    å‚æ•°è¯´æ˜ï¼š
        tracker_yaml: è·Ÿè¸ªå™¨é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼ŒåŒ…å«è·Ÿè¸ªå™¨çš„å‚æ•°è®¾ç½®
        frame_rate: è§†é¢‘å¸§ç‡ï¼Œç”¨äºè·Ÿè¸ªå™¨çš„æ—¶é—´è®¡ç®—ï¼Œé»˜è®¤30fps

    è¿”å›å€¼ï¼š
        åˆå§‹åŒ–å¥½çš„è·Ÿè¸ªå™¨å®ä¾‹
    """
    # åŠ è½½å¹¶è§£æé…ç½®æ–‡ä»¶
    try:
        tracker_cfg = IterableSimpleNamespace(**yaml_load(check_yaml(tracker_yaml)))
    except Exception as e:
        print(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        # ä½¿ç”¨é»˜è®¤é…ç½®
        tracker_cfg = IterableSimpleNamespace(tracker_type="bytetrack")

    tracker_type = getattr(tracker_cfg, 'tracker_type', 'bytetrack')
    # æ£€æŸ¥è·Ÿè¸ªå™¨ç±»å‹æ˜¯å¦æ”¯æŒ
    if tracker_type not in TRACKER_MAP:
        raise ValueError(f"ä¸æ”¯æŒçš„è·Ÿè¸ªå™¨ç±»å‹: {tracker_type}")
    return TRACKER_MAP[tracker_type](args=tracker_cfg, frame_rate=frame_rate)

def mouse_callback(event, x, y, flags, param):
    """
    é¼ æ ‡å›è°ƒå‡½æ•° - ç‚¹å‡»æ˜¾ç¤ºåæ ‡ä½ç½®
    """
    _ = flags, param  # å¿½ç•¥æœªä½¿ç”¨çš„å‚æ•°
    if event == cv2.EVENT_LBUTTONDOWN:
        print(f"Mouse click at: ({x}, {y})")
    elif event == cv2.EVENT_RBUTTONDOWN:
        print(f"Right click at: ({x}, {y})")

def draw_tracks(frame, track_history):
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶ç›®æ ‡è½¨è¿¹å’ŒIDæ ‡è¯†

    è½¨è¿¹å¯è§†åŒ–è¯´æ˜ï¼š
    - ç»¿è‰²çº¿æ¡ï¼šç›®æ ‡çš„å†å²ç§»åŠ¨è½¨è¿¹
    - é»„è‰²æ•°å­—ï¼šç›®æ ‡çš„å”¯ä¸€IDï¼Œæ˜¾ç¤ºåœ¨è½¨è¿¹èµ·å§‹ç‚¹
    - IDæ•°å­—å¯èƒ½ä¸è¿ç»­ï¼ˆå¦‚1,3,9,30ï¼‰ï¼Œè¿™æ˜¯æ­£å¸¸ç°è±¡ï¼Œè¡¨ç¤ºä¸­é—´çš„IDå·²è¢«åˆ é™¤

    å‚æ•°è¯´æ˜ï¼š
        frame: å½“å‰è§†é¢‘å¸§
        track_history: åŒ…å«æ‰€æœ‰ç›®æ ‡è½¨è¿¹å†å²çš„å­—å…¸
                      æ ¼å¼: {track_id: [(x1,y1), (x2,y2), ...]}

    è¿”å›å€¼ï¼š
        ç»˜åˆ¶å®Œè½¨è¿¹çš„å›¾åƒå¸§
    """
    # éå†æ¯ä¸ªç›®æ ‡çš„è½¨è¿¹å†å²
    for track_id, track in track_history.items():
        # ç»˜åˆ¶è½¨è¿¹çº¿ï¼šå¦‚æœè½¨è¿¹ç‚¹æ•°å¤§äº1ï¼Œç”¨ç»¿è‰²çº¿æ¡è¿æ¥æ‰€æœ‰å†å²ä½ç½®
        if len(track) > 1:
            points = np.array(track).astype(np.int32).reshape((-1, 1, 2))
            cv2.polylines(frame, [points], isClosed=False, color=(0, 255, 0), thickness=2)

        # ç»˜åˆ¶ç›®æ ‡IDï¼šåœ¨è½¨è¿¹èµ·å§‹ç‚¹æ˜¾ç¤ºé»„è‰²IDæ•°å­—
        if len(track) > 0:
            start_point = tuple(np.array(track[0]).astype(int))
            cv2.putText(
                frame,
                str(track_id),  # æ˜¾ç¤ºè½¨è¿¹IDï¼ˆå¯èƒ½ä¸è¿ç»­ï¼Œå¦‚1,3,9,30ç­‰ï¼‰
                start_point,    # æ˜¾ç¤ºä½ç½®ï¼šè½¨è¿¹çš„ç¬¬ä¸€ä¸ªç‚¹ï¼ˆèµ·å§‹ä½ç½®ï¼‰
                cv2.FONT_HERSHEY_SIMPLEX,
                3,              # å­—ä½“å¤§å°
                (0, 255, 255),  # é»„è‰² (BGRæ ¼å¼: è“=0, ç»¿=255, çº¢=255)
                3,              # å­—ä½“ç²—ç»†
                cv2.LINE_AA     # æŠ—é”¯é½¿
            )
    return frame

# åˆå§‹åŒ–YOLOæ¨¡å‹
# ä½¿ç”¨é¢„è®­ç»ƒçš„æƒé‡æ–‡ä»¶'last.pt'
model = YOLO("last.pt")

# åˆå§‹åŒ–ç›®æ ‡è·Ÿè¸ªå™¨
# ä½¿ç”¨æ”¹è¿›çš„ByteTracké…ç½®ï¼Œä¼˜åŒ–IDåˆ†é…æœºåˆ¶ï¼Œå‡å°‘IDæµªè´¹
# é…ç½®ç‰¹ç‚¹ï¼šæé«˜æ–°è½¨è¿¹åˆ›å»ºé˜ˆå€¼ï¼Œå¢åŠ è½¨è¿¹ç¼“å†²æ—¶é—´ï¼Œæ”¹å–„å…³è”ç²¾åº¦
tracker = initialize_tracker("data/bytetrack_improved.yaml")
# tracker = initialize_tracker("data/bytetrack.yaml")  # åŸå§‹é…ç½®ï¼ˆIDæµªè´¹è¾ƒå¤šï¼‰
# tracker = initialize_tracker("data/botsort.yaml")    # BoT-SORTï¼ˆéœ€è¦ReIDç‰¹å¾ï¼‰

# æ‰“å¼€è§†é¢‘æ–‡ä»¶
# æ³¨æ„ï¼šç¡®ä¿è§†é¢‘è·¯å¾„æ­£ç¡®ä¸”å¯è®¿é—®
video_path = "/data2/wuyuchen/Tracking_benchmark/UAV/æ— äººæœº/1.MOV"
cap = cv2.VideoCapture(video_path)

# è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯
fps = cap.get(cv2.CAP_PROP_FPS)  # è§†é¢‘å¸§ç‡
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # è§†é¢‘å®½åº¦
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # è§†é¢‘é«˜åº¦
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # æ€»å¸§æ•°

# è®¾ç½®å­å›¾åˆ†å‰²å‚æ•°
# ç”±äºåŸè§†é¢‘åˆ†è¾¨ç‡è¾ƒé«˜ï¼Œéœ€è¦åˆ†å—å¤„ç†ä»¥æé«˜æ•ˆç‡
sub_width = 960  # å­å›¾å®½åº¦
sub_height = 1080  # å­å›¾é«˜åº¦
cols = width // sub_width  # æ°´å¹³åˆ†å‰²æ•°
rows = height // sub_height  # å‚ç›´åˆ†å‰²æ•°

# åˆå§‹åŒ–è½¨è¿¹å†å²è®°å½•
# ä½¿ç”¨defaultdictè‡ªåŠ¨åˆ›å»ºæ–°ç›®æ ‡çš„è½¨è¿¹åˆ—è¡¨
track_history = defaultdict(lambda: [])

# åˆ›å»ºå¯è°ƒæ•´å¤§å°çš„çª—å£
window_name = "YOLOç›®æ ‡è·Ÿè¸ªç³»ç»Ÿ(å¤šçº¿ç¨‹ç‰ˆ) - æŒ‰Qé€€å‡º"
cv2.namedWindow(window_name, cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)  # å…è®¸è°ƒæ•´çª—å£å¤§å°å¹¶ä¿æŒæ¯”ä¾‹

print("ğŸ–¥ï¸  Window Controls:")
print("   - Drag window edges to resize")
print("   - Click top-right buttons to maximize/minimize/close")
print("   - Press Q to exit")
print("   - Press R to reset window size")
print("   - Press F to toggle fullscreen")
print("   - Press SPACE to pause/resume")
print("   - Left click to show coordinates")

# åˆå§‹åŒ–æ€§èƒ½ç»Ÿè®¡
frame_processing_times = []

# åˆå§‹åŒ–çª—å£æ§åˆ¶å˜é‡
is_fullscreen = False
is_paused = False
window_initialized = False
mouse_callback_set = False

# å¸§é˜Ÿåˆ—å’Œçº¿ç¨‹ç®¡ç†
frame_queue = queue.Queue(maxsize=10)

def read_frames():
    """
    å¤šçº¿ç¨‹å¸§è¯»å–å‡½æ•°
    åœ¨åå°çº¿ç¨‹ä¸­æŒç»­è¯»å–è§†é¢‘å¸§ï¼Œæé«˜å¤„ç†æ•ˆç‡
    """
    while True:
        ret, frame = cap.read()
        if not ret:
            frame_queue.put(None)  # è¡¨ç¤ºè§†é¢‘ç»“æŸ
            break
        frame_queue.put(frame)

# å¯åŠ¨è¯»å–çº¿ç¨‹
read_thread = threading.Thread(target=read_frames, daemon=True)
read_thread.start()

# ä¸»å¤„ç†å¾ªç¯
# ä½¿ç”¨tqdmæ˜¾ç¤ºå¤„ç†è¿›åº¦
with tqdm(total=total_frames, desc="Processing Video", unit="frame") as pbar:
    while True:
        # å¼€å§‹è®¡æ—¶
        frame_start_time = time.time()

        # åˆå§‹åŒ–å„é˜¶æ®µè®¡æ—¶å™¨
        timing = {
            "read_frame": 0,  # å¸§è¯»å–æ—¶é—´
            "predict": 0,     # ç›®æ ‡æ£€æµ‹æ—¶é—´
            "track": 0,       # ç›®æ ‡è·Ÿè¸ªæ—¶é—´
            "draw": 0,        # ç»˜åˆ¶æ˜¾ç¤ºæ—¶é—´
        }

        # ä»é˜Ÿåˆ—ä¸­è·å–å¸§
        read_start = time.time()
        frame = frame_queue.get()
        if frame is None:  # å¦‚æœè¯»å–ç»“æŸï¼Œé€€å‡ºå¾ªç¯
            break
        timing["read_frame"] = time.time() - read_start

        # åˆå§‹åŒ–å­˜å‚¨åˆ—è¡¨
        sub_frames = []  # å­˜å‚¨åˆ†å‰²åçš„å­å›¾
        detections = []  # å­˜å‚¨æ£€æµ‹ç»“æœ

        # å›¾åƒåˆ†å—å¤„ç†
        # å°†å¤§åˆ†è¾¨ç‡å›¾åƒåˆ†å‰²æˆå°å—è¿›è¡Œå¤„ç†
        for row in range(rows):
            for col in range(cols):
                # è®¡ç®—å½“å‰å­å›¾çš„åæ ‡
                x1 = col * sub_width
                y1 = row * sub_height
                x2 = x1 + sub_width
                y2 = y1 + sub_height

                # æå–å­å›¾
                sub_frame = frame[y1:y2, x1:x2]
                sub_frames.append(sub_frame)

        # YOLOç›®æ ‡æ£€æµ‹
        predict_start = time.time()
        # ä½¿ç”¨GPUè¿›è¡Œæ‰¹é‡æ£€æµ‹
        results = model.predict(source=sub_frames, device=0, verbose=False)
        timing["predict"] = time.time() - predict_start

        # ç›®æ ‡è·Ÿè¸ªå¤„ç†
        track_start = time.time()
        # å¤„ç†æ£€æµ‹ç»“æœï¼Œå°†å­å›¾åæ ‡æ˜ å°„å›åŸå›¾åæ ‡
        for i, result in enumerate(results):
            row = i // cols
            col = i % cols
            x_offset = col * sub_width
            y_offset = row * sub_height

            # åæ ‡è½¬æ¢
            for box in result.boxes.data.cpu().numpy():
                x1, y1, x2, y2, conf, cls = box[:6]
                # æ·»åŠ åç§»é‡å¾—åˆ°åŸå›¾åæ ‡
                x1 += x_offset
                x2 += x_offset
                y1 += y_offset
                y2 += y_offset
                detections.append([x1, y1, x2, y2, conf, cls])

        # ğŸ”§ æ·»åŠ å…¨å±€NMSå»é‡å¤„ç†ï¼Œé¿å…é‡å¤æ£€æµ‹å¯¼è‡´IDæµªè´¹
        if len(detections) > 0:
            detections_array = np.array(detections)
            # ä½¿ç”¨YOLOçš„NMSå‡½æ•°è¿›è¡Œå»é‡
            from ultralytics.utils.ops import non_max_suppression
            import torch

            # è½¬æ¢ä¸ºtensoræ ¼å¼ [x1, y1, x2, y2, conf, cls]
            detections_tensor = torch.from_numpy(detections_array).float().unsqueeze(0)

            # åº”ç”¨NMSå»é‡ï¼ŒIoUé˜ˆå€¼è®¾ä¸º0.5ä»¥å»é™¤é‡å¤æ£€æµ‹
            nms_results = non_max_suppression(
                detections_tensor,
                conf_thres=0.25,  # ç½®ä¿¡åº¦é˜ˆå€¼
                iou_thres=0.5,    # IoUé˜ˆå€¼ï¼Œå»é™¤é‡å¤æ£€æµ‹
                max_det=300       # æœ€å¤§æ£€æµ‹æ•°é‡
            )[0]

            if nms_results is not None and len(nms_results) > 0:
                detections = nms_results.cpu().numpy()
            else:
                detections = np.array([])
        else:
            detections = np.array([])

        # å°†æ£€æµ‹ç»“æœè½¬æ¢ä¸ºYOLOçš„Boxesæ ¼å¼
        if len(detections) > 0:
            detections = Boxes(detections, frame.shape)
        else:
            detections = Boxes(np.empty((0, 6)), frame.shape)

        # æ›´æ–°ç›®æ ‡è·Ÿè¸ªå™¨
        tracks = tracker.update(detections, frame)
        timing["track"] = time.time() - track_start

        # ç»˜åˆ¶æ£€æµ‹å’Œè·Ÿè¸ªç»“æœ
        draw_start = time.time()

        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„è·Ÿè¸ªç»“æœ
        if len(tracks) > 0 and tracks.ndim == 2:
            # æœ‰è·Ÿè¸ªç»“æœæ—¶çš„å¤„ç†
            all_detections = Results(frame, path="", names=model.predictor.model.names, boxes=torch.as_tensor(tracks[:, :-1]))

            # ç»˜åˆ¶æ£€æµ‹æ¡†
            anno_frame = all_detections.plot(img=frame, line_width=5, font_size=5)

            # æ›´æ–°å’Œç»˜åˆ¶è½¨è¿¹
            boxes = all_detections.boxes.xywh.cpu()
            track_ids = all_detections.boxes.id.int().cpu().tolist()
            for box, track_id in zip(boxes, track_ids):
                x, y, w, h = box
                track = track_history[track_id]
                track.append((float(x), float(y)))  # è®°å½•ç›®æ ‡ä¸­å¿ƒç‚¹
            annotated_frame = draw_tracks(anno_frame, track_history)
        else:
            # æ²¡æœ‰è·Ÿè¸ªç»“æœæ—¶ï¼Œåªç»˜åˆ¶åŸå§‹å¸§å’Œç°æœ‰è½¨è¿¹
            annotated_frame = draw_tracks(frame, track_history)
            track_ids = []  # ç©ºçš„è·Ÿè¸ªIDåˆ—è¡¨

        # è°ƒæ•´å›¾åƒå¤§å°ç”¨äºæ˜¾ç¤º
        resized_image = cv2.resize(annotated_frame, (1920, 1080))
        timing["draw"] = time.time() - draw_start

        # è®°å½•æœ¬å¸§å¤„ç†æ—¶é—´
        frame_end_time = time.time()
        frame_time = frame_end_time - frame_start_time
        frame_processing_times.append({"total": frame_time, **timing})

        # åœ¨å›¾åƒä¸Šæ·»åŠ ä¿¡æ¯æ–‡å­—ï¼ˆä½¿ç”¨è‹±æ–‡é¿å…å­—ä½“é—®é¢˜ï¼‰- æ— èƒŒæ™¯æ¡†
        info_text = [
            f"Frame: {pbar.n}/{total_frames}",
            f"Progress: {(pbar.n/total_frames)*100:.1f}%",
            f"Speed: {1/frame_time:.1f} FPS" if frame_time > 0 else "Speed: Calculating...",
            f"Objects: {len(track_ids) if 'track_ids' in locals() else 0}",
            f"Tracker: ByteTrack (Improved) | Yellow ID = Track Start Point",
            f"Q:Exit | R:Reset | F:Fullscreen | Space:Pause | Click for coordinates"
        ]

        # ç›´æ¥ç»˜åˆ¶ä¿¡æ¯æ–‡å­—ï¼ˆæ— èƒŒæ™¯æ¡†ï¼‰
        for i, text in enumerate(info_text):
            cv2.putText(resized_image, text, (20, 35 + i*25),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

        # æ˜¾ç¤ºå¤„ç†åçš„å›¾åƒ
        cv2.imshow(window_name, resized_image)

        # åˆå§‹åŒ–çª—å£è®¾ç½®ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡æ˜¾ç¤ºæ—¶æ‰§è¡Œï¼‰
        if not window_initialized:
            try:
                # ç­‰å¾…çª—å£å®Œå…¨åˆ›å»º
                cv2.waitKey(1)
                cv2.resizeWindow(window_name, 1280, 720)  # è®¾ç½®é»˜è®¤çª—å£å¤§å°ä¸º720p
                cv2.moveWindow(window_name, 100, 100)  # è®¾ç½®çª—å£åˆå§‹ä½ç½®
                window_initialized = True
                print("âœ… Window size and position set")
            except cv2.error as e:
                print(f"âš ï¸ Window setup failed: {e}")
                window_initialized = True  # é¿å…é‡å¤å°è¯•

        # å»¶è¿Ÿè®¾ç½®é¼ æ ‡å›è°ƒï¼ˆåœ¨çª—å£ç¨³å®šåï¼‰
        if window_initialized and not mouse_callback_set and pbar.n > 10:
            try:
                # æ£€æŸ¥çª—å£æ˜¯å¦å­˜åœ¨
                if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) >= 1:
                    cv2.setMouseCallback(window_name, mouse_callback)
                    mouse_callback_set = True
                    print("âœ… Mouse callback set")
                else:
                    # çª—å£è¿˜ä¸å¯è§ï¼Œç»§ç»­ç­‰å¾…
                    pass
            except cv2.error as e:
                print(f"âš ï¸ é¼ æ ‡å›è°ƒè®¾ç½®å¤±è´¥: {e}")
                mouse_callback_set = True  # é¿å…é‡å¤å°è¯•

        # ä¿å­˜å¤„ç†åçš„å›¾åƒï¼ˆæ¯30å¸§ä¿å­˜ä¸€æ¬¡ï¼‰
        if pbar.n % 30 == 0:  # æ¯30å¸§ä¿å­˜ä¸€å¼ 
            output_dir = "tracking_output_multi_thread"
            output_path = f"{output_dir}/frame_{pbar.n:06d}.jpg"
            os.makedirs(output_dir, exist_ok=True)
            cv2.imwrite(output_path, resized_image)
            print(f"ä¿å­˜å›¾ç‰‡: {output_path}")

        # æ›´æ–°è¿›åº¦æ¡
        pbar.update(1)

        # é”®ç›˜äº‹ä»¶å¤„ç†
        key = cv2.waitKey(1) & 0xFF
        if key == ord("q"):  # æŒ‰Qé€€å‡º
            break
        elif key == ord("r"):  # æŒ‰Ré‡ç½®çª—å£å¤§å°
            try:
                cv2.resizeWindow(window_name, 1280, 720)
                cv2.moveWindow(window_name, 100, 100)
                print("âœ… Window reset to default size")
            except cv2.error as e:
                print(f"âš ï¸ Window reset failed: {e}")
        elif key == ord("f"):  # æŒ‰Fåˆ‡æ¢å…¨å±
            try:
                if not is_fullscreen:
                    cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
                    is_fullscreen = True
                    print("âœ… Fullscreen mode enabled")
                else:
                    cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)
                    is_fullscreen = False
                    print("âœ… Windowed mode enabled")
            except cv2.error as e:
                print(f"âš ï¸ Fullscreen toggle failed: {e}")
        elif key == ord(" "):  # æŒ‰ç©ºæ ¼æš‚åœ/ç»§ç»­
            is_paused = not is_paused
            if is_paused:
                print("â¸ï¸ Paused - Press SPACE to resume")
                while is_paused:
                    key = cv2.waitKey(30) & 0xFF
                    if key == ord(" "):
                        is_paused = False
                        print("â–¶ï¸ Resumed")
                    elif key == ord("q"):
                        break

# æ¸…ç†èµ„æºå’Œæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
print("\nğŸ”„ æ­£åœ¨æ¸…ç†èµ„æº...")

# ä¿å­˜æœ€åä¸€å¸§
if 'resized_image' in locals():
    output_dir = "tracking_output_multi_thread"
    os.makedirs(output_dir, exist_ok=True)
    cv2.imwrite(f"{output_dir}/final_frame.jpg", resized_image)
    print(f"âœ… æœ€åä¸€å¸§å·²ä¿å­˜ä¸º {output_dir}/final_frame.jpg")

# é‡Šæ”¾è§†é¢‘æ•è·å¯¹è±¡å’Œçª—å£
cap.release()
cv2.destroyAllWindows()
print("âœ… èµ„æºæ¸…ç†å®Œæˆ")

# è®¡ç®—å¹¶æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
if frame_processing_times:
    print(f"\nğŸ“Š å¤„ç†å®Œæˆï¼å…±å¤„ç† {len(frame_processing_times)} å¸§")

    # è®¡ç®—å¹³å‡å¤„ç†æ—¶é—´ï¼ˆè·³è¿‡ç¬¬ä¸€å¸§ï¼Œå› ä¸ºå¯èƒ½åŒ…å«åˆå§‹åŒ–å¼€é”€ï¼‰
    if len(frame_processing_times) > 1:
        valid_times = frame_processing_times[1:]
        average_stats = {}
        for key in valid_times[0].keys():
            average_stats[key] = sum(times[key] for times in valid_times) / len(valid_times)

        print("\nâ±ï¸ å¹³å‡å¸§å¤„ç†æ—¶é—´:")
        for key, value in average_stats.items():
            if key != "total":
                percentage = (value / average_stats['total']) * 100 if average_stats['total'] > 0 else 0
                print(f"  {key}: {value:.4f}s ({percentage:.2f}%)")
        print(f"æ€»è®¡: {average_stats['total']:.4f}s")

        # è®¡ç®—å¹³å‡FPS
        if average_stats['total'] > 0:
            avg_fps = 1 / average_stats['total']
            print(f"å¹³å‡å¤„ç†é€Ÿåº¦: {avg_fps:.2f} FPS")
    else:
        print("å¤„ç†å¸§æ•°ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ç»Ÿè®¡ä¿¡æ¯")
else:
    print("æœªå¤„ç†ä»»ä½•å¸§")

print("\nğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆï¼")
